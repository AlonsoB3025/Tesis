{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba0f5e9",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3441ec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T23:50:34.635736Z",
     "iopub.status.busy": "2025-09-30T23:50:34.635165Z",
     "iopub.status.idle": "2025-09-30T23:50:34.641176Z",
     "shell.execute_reply": "2025-09-30T23:50:34.640630Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015386,
     "end_time": "2025-09-30T23:50:34.642686",
     "exception": false,
     "start_time": "2025-09-30T23:50:34.627300",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "RAW_DIR = \"data/raw/\"\n",
    "PROCESSED_DIR = \"data/processed/\"\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf85210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T23:50:34.647913Z",
     "iopub.status.busy": "2025-09-30T23:50:34.647618Z",
     "iopub.status.idle": "2025-09-30T23:50:34.658562Z",
     "shell.execute_reply": "2025-09-30T23:50:34.658087Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014689,
     "end_time": "2025-09-30T23:50:34.659818",
     "exception": false,
     "start_time": "2025-09-30T23:50:34.645129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs: /Users/alonso/Downloads/Tesis_SIEM_ML/data/processed_logs/logs_normalizados.csv\n",
      "Predicciones dir: /Users/alonso/Downloads/Tesis_SIEM_ML/data/processed/predictions\n"
     ]
    }
   ],
   "source": [
    "# Parameters (papermill)\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_DIR = \"data/raw\"\n",
    "PROCESSED_DIR = \"data/processed\"\n",
    "PROCESSED_LOGS_DIR = \"data/processed_logs\"\n",
    "MODELS_DIR = \"data/processed/models\"\n",
    "PREDICTIONS_DIR = \"data/processed/predictions\"\n",
    "RANDOM_STATE = 42\n",
    "LOGS_FILE = \"logs_normalizados.csv\"  \n",
    "\n",
    "# Normalizar rutas y crear carpetas de salida si no existen\n",
    "RAW_DIR = Path(RAW_DIR)\n",
    "PROCESSED_DIR = Path(PROCESSED_DIR)\n",
    "PROCESSED_LOGS_DIR = Path(PROCESSED_LOGS_DIR)\n",
    "MODELS_DIR = Path(MODELS_DIR); MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PREDICTIONS_DIR = Path(PREDICTIONS_DIR); PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for d in (PROCESSED_DIR, PROCESSED_LOGS_DIR, MODELS_DIR, PREDICTIONS_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Rutas de entrada/salida típicas\n",
    "ruta_logs = PROCESSED_LOGS_DIR / LOGS_FILE\n",
    "print(\"Logs:\", ruta_logs.resolve())\n",
    "print(\"Predicciones dir:\", PREDICTIONS_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b238c2",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ac710a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T23:50:34.663955Z",
     "iopub.status.busy": "2025-09-30T23:50:34.663711Z",
     "iopub.status.idle": "2025-09-30T23:50:36.290553Z",
     "shell.execute_reply": "2025-09-30T23:50:36.290136Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 1.629562,
     "end_time": "2025-09-30T23:50:36.291147",
     "exception": true,
     "start_time": "2025-09-30T23:50:34.661585",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Procesando modelo: rf_real ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required by RandomForestClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m     df_encoded \u001b[38;5;241m=\u001b[39m df_encoded[\u001b[38;5;28mlist\u001b[39m(encoders\u001b[38;5;241m.\u001b[39mkeys())]\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# Hacer predicción\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclave\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m modelo\u001b[38;5;241m.\u001b[39mpredict(df_encoded)\n\u001b[1;32m     81\u001b[0m     resultados[clave] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclave\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResumen de predicciones:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:638\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    636\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    640\u001b[0m     X,\n\u001b[1;32m    641\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[1;32m    642\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    643\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    644\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[1;32m    645\u001b[0m )\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:1130\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1132\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1133\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1134\u001b[0m         )\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1137\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required by RandomForestClassifier."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# RUTAS\n",
    "ruta_logs = \"/Users/alonso/Downloads/Tesis_SIEM_ML/data/processed_logs/logs_normalizados.csv\"\n",
    "\n",
    "# Rutas a modelos y encoders ya entrenados\n",
    "ruta_modelos = {\n",
    "    \"rf_real\": \"/Users/alonso/Downloads/Tesis_SIEM_ML/modelos/rf_modelo_supervisado_real.pkl\",\n",
    "    \"rf_bal\": \"/Users/alonso/Downloads/Tesis_SIEM_ML/modelos/rf_modelo_supervisado_balanceado.pkl\",\n",
    "    \"if\": \"/Users/alonso/Downloads/Tesis_SIEM_ML/modelos/modelo_isolation_forest.pkl\"\n",
    "}\n",
    "\n",
    "ruta_encoders = {\n",
    "    \"rf_real\": \"/Users/alonso/Downloads/Tesis_SIEM_ML/modelos/label_encoders_supervisado_real.pkl\",\n",
    "    \"rf_bal\": \"/Users/alonso/Downloads/Tesis_SIEM_ML/modelos/label_encoders_supervisado_balanceado.pkl\",\n",
    "    \"if\": \"/Users/alonso/Downloads/Tesis_SIEM_ML/modelos/label_encoders_isolation_forest.pkl\"\n",
    "}\n",
    "\n",
    "# FUNCIONES AUXILIARES\n",
    "\n",
    "def aplicar_label_encoding_robusto(df, encoders):\n",
    "    df_encoded = df.copy()\n",
    "    for col, encoder in encoders.items():\n",
    "        df_encoded[col] = df_encoded[col].fillna(\"\").astype(str)\n",
    "        clases = encoder.classes_\n",
    "        mapa = {clase: i for i, clase in enumerate(clases)}\n",
    "        df_encoded[col] = df_encoded[col].apply(lambda val: mapa.get(val, -1))\n",
    "    return df_encoded\n",
    "\n",
    "# CARGA DE LOGS\n",
    "df = pd.read_csv(ruta_logs)\n",
    "\n",
    "# --- Normaliza nombres de columnas para evitar fallos por mayúsculas/puntos/espacios ---\n",
    "original_cols = df.columns.tolist()\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    "      .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "# Mapea alias conocidos -> nombre canónico\n",
    "rename_map = {\n",
    "    \"event.channel\": \"channel\",\n",
    "    \"event_channel\": \"channel\",\n",
    "    \"log.channel\": \"channel\",\n",
    "    \"log_level\": \"log_level\",        \n",
    "    \"message\": \"description\",\n",
    "    \"event.original\": \"description\",\n",
    "    \"event_action\": \"action\",\n",
    "    \"event.action\": \"action\",\n",
    "    \"user.name\": \"src_user\",\n",
    "    \"related.user\": \"src_user\",\n",
    "}\n",
    "df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns}, inplace=True)\n",
    "\n",
    "# --- Asegura columnas mínimas ---\n",
    "required = [\"description\", \"object_type\", \"channel\", \"log_level\", \"action\"]\n",
    "for col in required:\n",
    "    if col not in df.columns:\n",
    "        df[col] = \"desconocido\"  # o pd.NA si prefieres\n",
    "\n",
    "faltantes = [c for c in required if c not in original_cols and c in df.columns]\n",
    "\n",
    "# PREDICCIÓN CON TODOS LOS MODELOS \n",
    "resultados = {}\n",
    "\n",
    "for clave in ruta_modelos:\n",
    "    print(f\"=== Procesando modelo: {clave} ===\")\n",
    "    modelo = joblib.load(ruta_modelos[clave])\n",
    "    encoders = joblib.load(ruta_encoders[clave])\n",
    "\n",
    "    df_copia = df.copy()\n",
    "    df_encoded = aplicar_label_encoding_robusto(df_copia, encoders)\n",
    "    df_encoded = df_encoded[list(encoders.keys())]\n",
    "\n",
    "    # Hacer predicción\n",
    "    df[f\"pred_{clave}\"] = modelo.predict(df_encoded)\n",
    "    resultados[clave] = df[f\"pred_{clave}\"].value_counts()\n",
    "\n",
    "print(\"Resumen de predicciones:\")\n",
    "for clave, valores in resultados.items():\n",
    "    print(f\"\\nModelo: {clave}\")\n",
    "    print(valores)\n",
    "\n",
    "# (Opcional) Guardar el resultado con las predicciones\n",
    "df.to_csv(PREDICTIONS_DIR / \"resultados_predicciones.csv\",\n",
    "          index=False, encoding=\"utf-8-sig\")\n",
    "print(\"\\nArchivo guardado como 'resultados_predicciones.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334773b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mostrar ejemplos concretos de predicción\n",
    "print(\"\\n=== EJEMPLOS DE PREDICCIONES ===\")\n",
    "columnas_pred = ['pred_rf_real', 'pred_rf_bal', 'pred_if']\n",
    "columnas_mostrar = columnas_pred + [col for col in df.columns if col not in columnas_pred]\n",
    "df_ejemplos = df[columnas_mostrar].head(5)\n",
    "print(df_ejemplos.to_string(index=False))\n",
    "\n",
    "# Mostrar ejemplos positivos detectados por RF real\n",
    "print(\"\\n=== EJEMPLOS POSITIVOS DETECTADOS POR RF REAL ===\")\n",
    "ej_rf_real = df[df['pred_rf_real'] == 1][columnas_mostrar].head(5)\n",
    "print(ej_rf_real.to_string(index=False))\n",
    "\n",
    "# Mostrar ejemplos positivos detectados por RF balanceado\n",
    "print(\"\\n=== EJEMPLOS POSITIVOS DETECTADOS POR RF BALANCEADO ===\")\n",
    "ej_rf_bal = df[df['pred_rf_bal'] == 1][columnas_mostrar].head(5)\n",
    "print(ej_rf_bal.to_string(index=False))\n",
    "\n",
    "# Mostrar ejemplos positivos detectados por Isolation Forest\n",
    "print(\"\\n=== EJEMPLOS POSITIVOS DETECTADOS POR ISOLATION FOREST ===\")\n",
    "ej_if = df[df['pred_if'] == 1][columnas_mostrar].head(5)\n",
    "print(ej_if.to_string(index=False))\n",
    "\n",
    "# Mostrar ejemplos donde los modelos no coinciden\n",
    "print(\"\\n=== EJEMPLOS DONDE LOS MODELOS NO COINCIDEN ===\")\n",
    "df_diferencias = df[\n",
    "    (df['pred_rf_real'] != df['pred_rf_bal']) |\n",
    "    (df['pred_rf_real'] != df['pred_if']) |\n",
    "    (df['pred_rf_bal'] != df['pred_if'])\n",
    "]\n",
    "df_diferencias_mostrar = df_diferencias[columnas_mostrar].head(5)\n",
    "print(df_diferencias_mostrar.to_string(index=False))\n",
    "\n",
    "# Guardar ejemplos discrepantes en un archivo CSV para revisión adicional\n",
    "# df_diferencias_mostrar.to_csv(\"/Users/alonso/Downloads/Tesis_SIEM_ML/data/ejemplos_discrepantes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd2ddf7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== INFORMES DETALLADOS CON EXPLICACIÓN DE ANOMALÍA ===\")\n",
    "\n",
    "# Columnas necesarias\n",
    "columnas_pred = ['pred_rf_real', 'pred_rf_bal', 'pred_if']\n",
    "columnas_mostrar = columnas_pred + [\n",
    "    col for col in df.columns if col in ['timestamp', 'src_user', 'action', 'description', 'object_type', 'channel', 'log_level']\n",
    "]\n",
    "\n",
    "# Selección de ejemplos\n",
    "df_ejemplos = df[columnas_mostrar].head(5)\n",
    "\n",
    "# Revisión de cada evento\n",
    "for idx, row in df_ejemplos.iterrows():\n",
    "    print(f\"\\n EVENTO {idx+1} - ANÁLISIS DETALLADO\")\n",
    "    print(f\" Fecha y hora: {row['timestamp']}\")\n",
    "    print(f\" Usuario: {row['src_user']}\")\n",
    "    print(f\" Acción: {row['action']}\")\n",
    "    print(f\" Descripción: {row['description']}\")\n",
    "    print(f\" Objeto afectado: {row['object_type']}\")\n",
    "    print(f\" Canal: {row['channel']}\")\n",
    "    print(f\" Nivel del log: {row['log_level']}\")\n",
    "\n",
    "    print(\"\\n RESPUESTA DE LOS MODELOS:\")\n",
    "\n",
    "    # Random Forest Real\n",
    "    if row['pred_rf_real'] == 1:\n",
    "        print(\" [RF Real] Detectó posible AMENAZA basada en datos reales.\")\n",
    "    else:\n",
    "        print(\" [RF Real] No considera este evento riesgoso.\")\n",
    "\n",
    "    # Random Forest Balanceado\n",
    "    if row['pred_rf_bal'] == 1:\n",
    "        print(\" [RF Balanceado] También lo detectó como AMENAZA.\")\n",
    "    else:\n",
    "        print(\" [RF Balanceado] Evento clasificado como normal.\")\n",
    "\n",
    "    # Isolation Forest\n",
    "    if row['pred_if'] in [1, -1]:\n",
    "        print(\" [Isolation Forest] Detectó una ANOMALÍA.\")\n",
    "        print(\" Posible explicación:\")\n",
    "\n",
    "        # Explicación basada en heurística\n",
    "        if pd.isna(row['src_user']) or '$' in str(row['src_user']):\n",
    "            print(\"    • El evento fue ejecutado por una cuenta de sistema o servicio, lo cual puede ocultar actividad maliciosa.\")\n",
    "        if \"credential\" in str(row['action']).lower():\n",
    "            print(\"    • Se accedió al gestor de credenciales, lo que suele ser inusual en logs normales.\")\n",
    "        if \"permissions\" in str(row['action']).lower():\n",
    "            print(\"    • Hubo un cambio de permisos, lo cual puede estar asociado a escalamiento de privilegios.\")\n",
    "        if row['log_level'] in ['critical', 'error']:\n",
    "            print(\"    • El nivel del log es alto, indicando un posible incidente o fallo importante.\")\n",
    "        if row['channel'] not in ['System', 'Security']:\n",
    "            print(\"    • El evento fue registrado en un canal poco común.\")\n",
    "        if str(row['object_type']).strip() == '-' or pd.isna(row['object_type']):\n",
    "            print(\"    • No se especifica el tipo de objeto afectado, lo cual puede indicar evasión de registro.\")\n",
    "\n",
    "    else:\n",
    "        print(\" [Isolation Forest] No detectó ninguna anomalía.\")\n",
    "\n",
    "    print(\"\\n CONCLUSIÓN:\")\n",
    "    if row['pred_rf_real'] == 1 or row['pred_rf_bal'] == 1 or row['pred_if'] in [1, -1]:\n",
    "        print(\" Este evento requiere revisión humana. Múltiples señales apuntan a comportamiento sospechoso.\")\n",
    "    else:\n",
    "        print(\" El evento es considerado normal por todos los modelos.\")\n",
    "\n",
    "print(\"\\n Fin del informe detallado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.708288,
   "end_time": "2025-09-30T23:50:36.609258",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/prediccion_ataques2.ipynb",
   "output_path": "notebooks/_executed/prediccion_ataques2.20250930_185033.executed.ipynb",
   "parameters": {
    "PROCESSED_DIR": "data/processed/",
    "RANDOM_STATE": 42,
    "RAW_DIR": "data/raw/"
   },
   "start_time": "2025-09-30T23:50:33.900970",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}